				<exercises>

					<p><exercise><!-- xml:id="ex-" -->
						<statement>
							<aside><p>(Source: <xref ref="ref-PS" />, Chapter 4, Exercise 4.4.6) </p></aside>

							Consider the matrices:
							<m> A = \begin{bmatrix} 1 \amp 2 \amp 3\\ 2 \amp 1 \amp 7 \end{bmatrix},
								B = \begin{bmatrix} 3 \amp -1 \amp 2 \\ -3 \amp 2 \amp 1 \end{bmatrix},
								C = \begin{bmatrix} 1 \amp 2 \\ 3 \amp 1 \end{bmatrix},
								D = \begin{bmatrix} -1 \amp 2 \\ 2 \amp -3 \end{bmatrix}, </m>
							and <m>
								E = \begin{bmatrix} 2 \\ 3 \end{bmatrix}.</m>  Find the following if possible. If it is not possible, explain why.
							<ol cols="3">
								<li>
									<m> -3A </m>
								</li>
								<li> 
									<m> 3B - A </m>
								</li>
								<li> 
									<m> AC </m>
								</li>
								<li>
									<m> CB </m>
								</li>
								<li> 
									<m> AE </m>
								</li>
								<li>
									<m> EA </m>
								</li>
							</ol>
						</statement>
						<hint xml:id="hint-matrix-product">
							<aside><p>(Source: <xref ref="ref-PS" />, Chapter 4, Definition 4.21) </p></aside>
							Recall: Let <m>A=[a_{i j}]</m> be an <m>m\times n</m>-matrix, and let <m>B=[b_{j k}]</m> be an <m>n\times p</m>-matrix. Then their <em>product</em> is the <m>m\times p</m>-matrix
							<m>AB= [c_{ik}]</m> whose <m>(i,k)</m>-entry is defined by
							<me>
								c_{ik} = a_{i1}b_{1k}+a_{i2}b_{2k}+...+a_{in}b_{nk}.
							</me>
						</hint>
						<solution>
							<ol>
								<li><solution>
									<md><mrow> -3A \amp= -3\begin{bmatrix} 1 \amp 2 \amp 3\\ 2 \amp 1 \amp 7 \end{bmatrix}
										=\begin{bmatrix} -3 \amp -6 \amp -9\\ -6 \amp -3 \amp -21 \end{bmatrix}.</mrow></md>
								</solution></li>
								<li><solution> 
									<md><mrow> 3B - A \amp =3\begin{bmatrix} 3 \amp -1 \amp 2 \\ -3 \amp 2 \amp 1 \end{bmatrix} - \begin{bmatrix} 1 \amp 2 \amp 3\\ 2 \amp 1 \amp 7 \end{bmatrix}</mrow>
									<mrow> \amp =
										\begin{bmatrix} 3\cdot 3 -1 \amp 3\cdot (-1) - 2 \amp 3\cdot 2 - 3 \\ 3\cdot (-3) -2 \amp 3\cdot 2 -1 \amp 3\cdot 1 -7 \end{bmatrix}</mrow>
									<mrow> \amp =
										\begin{bmatrix} 8 \amp -5 \amp 3 \\ -11 \amp 5 \amp -4 \end{bmatrix}.</mrow>
									</md>
								</solution></li>
								<li><solution> 
									We cannot multiply these matrices as their sizes do not match up: the number of columns in <m>A</m> does not coincide with the number of rows in <m>C</m>.
								</solution></li>
								<li><solution>
									<md><mrow> CB \amp = \begin{bmatrix} 1 \amp 2 \\ 3 \amp 1 \end{bmatrix}\begin{bmatrix} 3 \amp -1 \amp 2 \\ -3 \amp 2 \amp 1 \end{bmatrix}</mrow>
									<mrow>\amp = \begin{bmatrix} 1 \cdot 3 + 2\cdot (-3) \amp 1\cdot (-1) + 2\cdot 2 \amp 1\cdot 2 + 2\cdot 1 \\ 3 \cdot 3 + 1\cdot (-3) \amp 3\cdot (-1) + 1\cdot 2 \amp 3\cdot 2 + 1\cdot 1 \end{bmatrix}</mrow>
									<mrow>\amp = \begin{bmatrix} -3 \amp 3 \amp 4 \\ 6 \amp -1 \amp 7 \end{bmatrix}.</mrow></md>
								</solution></li>
								<li><solution> 
									We cannot multiply these matrices as their sizes do not match up: the number of columns in <m>A</m> does not coincide with the number of rows in <m>E</m>.
								</solution></li>
								<li><solution>
									We cannot multiply these matrices as their sizes do not match up: the number of columns in <m>E</m> does not coincide with the number of rows in <m>A</m>.
								</solution></li>
							</ol>
						</solution>
						<answer>
							<ol>
								<li><answer>
									<md><mrow> -3A \amp=\begin{bmatrix} -3 \amp -6 \amp -9\\ -6 \amp -3 \amp -21 \end{bmatrix}.</mrow></md>
								</answer></li>
								<li><answer> 
									<md><mrow> 3B - A \amp =
										\begin{bmatrix} 8 \amp -5 \amp 3 \\ -11 \amp 5 \amp -4 \end{bmatrix}.</mrow>
									</md>
								</answer></li>
								<li><answer> 
									Does not exist.
								</answer></li>
								<li><answer>
									<md><mrow> CB = \begin{bmatrix} -3 \amp 3 \amp 4 \\ 6 \amp -1 \amp 7 \end{bmatrix}.</mrow></md>
								</answer></li>
								<li><answer> 
									Does not exist.
								</answer></li>
								<li><answer>
									Does not exist.
								</answer></li>
							</ol>
						</answer>
					</exercise></p>




					<p><exercise><!-- xml:id="ex-" -->
						<statement>
							<aside><p> (Source: <xref ref="ref-KN" />, Chapter 2, Exercise 2.3.29) </p></aside>
							Let <m>A</m> and <m>B</m> be <m>n \times n</m> matrices for which the system  of equations  <m>A\mathbf{x} = \mathbf{0}</m> and <m>B\mathbf{x} = \mathbf{0}</m> each only have the trivial solution <m>\mathbf{x} = \mathbf{0}</m>.  Show that the system <m>AB \mathbf{x} = \mathbf{0}</m> has only the trivial solution.
						</statement>
						<hint>
							Assume that <m>\mathbf{y}</m> is a solution to the system <m>AB \mathbf{x} = \mathbf{0}</m>. Use the assumptions to conclude that we must have <m>\mathbf{y}=\mathbf{0}</m>.
						</hint>
						<hint>
							Remember that <m>AB \mathbf{x} = A(B \mathbf{x}) =(AB) \mathbf{x}</m>.
						</hint>
						<solution>
							Take any vector <m>\mathbf{y}</m> with <m>n</m> components such that <m>AB \mathbf{y} = \mathbf{0}</m>. This means that <m>B \mathbf{y}</m> is a solution to the system of equations  <m>A\mathbf{x} = \mathbf{0}</m> which, by assumption, only has the trivial solution. In other words, <m>B \mathbf{y} = \mathbf{0}</m>. This similarly means that <m>\mathbf{y}</m> is a solution to the system of equations  <m>B\mathbf{x} = \mathbf{0}</m> which, again by assumption, only has the trivial solution. Thus, <m>\mathbf{y}=\mathbf{0}</m>. We have seen that the system <m>AB \mathbf{x} = \mathbf{0}</m> only has the trivial solution.
						</solution>
						<!--answer makes no sense here.-->
					</exercise></p>
					<p><exercise><!-- xml:id="ex-" -->
						<statement>
							<aside><p> (Source: <xref ref="ref-KN" />, Chapter 2, Exercise 2.3.27) </p></aside>
							 In each case either show the statement is true or give an example showing that it is false. (We assume that the matrices are of the correct size so that all matrix products which we consider make sense.)
	<ol>
		<li> 
			If <m> A^2 = I</m>, then <m> A = I</m>.
		</li>
		<li>
			If <m> AB = A</m>, then <m> B = I</m>. 
		</li>
		<li> 
		 	If <m> A </m> is square, then <m> (A^t)^3 = (A^3)^t</m>.
		</li>
		<li>
			If <m>A</m> is symmetric, then <m> I + A</m> is symmetric.
		</li>
		<li>
			If <m> AB = AC </m> and <m> A \ne 0</m>, then <m> B = C </m>. 
		</li>
		<li> 
		  	If <m> A \ne 0</m>, then <m> A^2 \ne 0</m>.
		 </li>		 
		<li>
			If <m> A </m> commutes with <m> A+B </m> then <m> A </m> commutes with <m> B </m>.
		</li>
	</ol>

			</statement>
				<hint xml:id="hint-def-symmetric">
					<p>See <xref ref="hint-matrix-transpose"/> for the definition of the transpose and <xref ref="hint-matrix-product"/> for the definition of matrix multiplication.</p>

					<p>Look back into <xref ref="ref-KN" />, Chapter 2, Theorem 2.1.1, for some properties of matrix operation.</p>
					
					<p>A square matrix <m>A</m> is called <em>symmetric</em> if <m>A=A^t</m>.</p>

					<p>Two square matrices <m>A,B</m> of the same size are said to <em>commute</em> if <m>AB=BA</m>.</p>
				</hint>
				<hint>
					All counterexamples can be chosen to be of size <m>2\times 2</m>.
				</hint>
				<solution>
					<ol>
					<li><solution> 
						<em>False:</em> Take <m> A =\begin{bmatrix} 0 \amp 1 \\ 1 \amp 0 \end{bmatrix}\neq I</m>, which satisfies <m> A^2 = I</m>.
					</solution></li>
					<li><solution>
						<em>False:</em> Take <m>A=B=\begin{bmatrix} 1 \amp 0 \\ 0 \amp 0\end{bmatrix}\neq I</m>, which satisfy <m> AB = A</m>.
					</solution></li>
					<li><solution> 
						<!--If <m> A </m> is square, then <m> (A^t)^3 = (A^3)^t</m>.-->
						<em>True:</em> We will prove that <m>B^t A^t=(AB)^t</m>, which will imply our claim because
						<me>
							(A^t)^3 = (A^t)(A^t)(A^t) = A^t(AA)^t = ((AA)A)^t = (A^3)^t.
						</me>
						For this proof, let us write <m>A_{i,j}</m> for the <m>(i,j)</m>-entry of <m>A</m>. Thus, we know from <xref ref="hint-matrix-product"/> that the <m>(i,k)</m>-entry of <m>AB</m> is given by:
						<me>
							(AB)_{i,k} = A_{i,1}B_{1,k}+A_{i,2}B_{2,k}+...+A_{i,n}B_{n,k}.
						</me>
						Recall further from <xref ref="hint-matrix-transpose"/> that <m>(B^t)_{k,j}=B_{j k}</m> and <m>(A^{T})_{j,i}=A_{i j}</m>, so that <m>B^t A^t</m> has <m>(k,i)</m>-entry 
						<md>
							<mrow>(B^t A^t)_{k,i} \amp= (B^t)_{k,1}(A^t)_{1,i}+(B^t)_{k,2}(A^t)_{2,i}+...+(B^t)_{k,n}(A^t)_{n,i}</mrow>
							<mrow>\amp = B{1,k}A_{i,1}+B_{2,k}A_{i,2}+...+B_{n,k}A_{i,n}</mrow>					
							<mrow>\amp = (AB)_{i,k}.</mrow>
						</md> 
						Again by <xref ref="hint-matrix-transpose"/>, <m>(i,k)</m>-entry of <m>AB</m> is the same as the <m>(k,i)</m>-entry of <m>(AB)^t</m>, so that 
						<me>
							(B^t A^t)_{k,i}= (AB)_{i,k} = ((AB)^t)_{k,i} .
						</me>
					 	We have shown that the <m>(k,i)</m>-entry of <m>B^t A^t</m> and of <m>(AB)^t</m> are identical. This means that <m>B^t A^t=(AB)^t</m>.
					</solution></li>
					<li><solution>
						<em>True:</em> <m>A</m> is symmetric means <m>A=A^t</m>. Thus, <m> (I + A)^{T} = I^{T}+A^{T} = I+A</m>,  where the first equality follows from Theorem 2.1.2(4) in <xref ref="ref-KN"/>. Thus, <m> I + A</m> is symmetric as well.
					</solution></li>
					<li><solution>
						<em>False:</em> Let
							<me>
								A=\begin{bmatrix} 1 \amp 0 \\ 0 \amp 0 \end{bmatrix},
								B=\begin{bmatrix} 1 \amp 0 \\ 1 \amp 1 \end{bmatrix},
								C=\begin{bmatrix} 1 \amp 0 \\ 0 \amp 1 \end{bmatrix}.
							</me>
						Then <m> A \ne 0</m> and 
						<me> AB = \begin{bmatrix} 1 \amp 0 \\ 0 \amp 0 \end{bmatrix} = A = AC, </me>
						but <m> B \neq C </m>. 
					</solution></li>
					<li><solution> 
					  	<em>False:</em> Let <m>A=\begin{bmatrix} 0 \amp 1 \\ 0 \amp 0 \end{bmatrix}</m>. Then <m> A^2 = 0</m>, even though <m>A\neq 0</m>.
					 </solution></li>							 
					<li><solution>
						<em>True:</em> We compute
						<me> A^2 + AB = A(A+B) \overset{(*)}{=} (A+B)A = A^2 + BA,</me>
						where <m>(*)</m> is by assumption that <m>A</m> commutes with <m>A+B</m>. If we substract <m>A^{2}</m> from both the left- and right-most side of the equation, we see that <m>AB=BA</m>, i.e. <m>A</m> commutes with <m> B </m>.
					</solution></li>
				</ol>
				</solution>
				<answer>
					<ol>
					<li>False.</li>
					<li>False.</li>
					<li>True.</li>
					<li>True.</li>
					<li>False.</li>
					<li>False.</li>							 
					<li>True.</li>
				</ol>
				</answer>

			</exercise></p>
			<p><exercise><!-- xml:id="ex-" -->
				<statement>
					<aside><p> (Adapted from: <xref ref="ref-KN" />, Chapter 2, Exercise 2.3.27) </p></aside>
					 In each case either show the statement is true or give an example showing that it is false. (We assume that the matrices are of the correct size so that all matrix products which we consider make sense.)
	<ol>
		<li>
			If <m> B</m>  has a row of zeros, so also does <m> AB</m> for all <m> A</m>.
		</li>y		
		<li>  
			If <m> A </m> has a row of zeros, so also does <m> AB </m> for all <m> B</m>.
		</li>
		<li>
			If <m> B</m> has a column of zeros, so also does <m> AB </m>  for all <m>A</m>.
		</li>
		<li> 
			If <m> AB </m> has a column of zeros for some <m>A\neq 0</m>, then so also does <m> B</m>.
		</li>
		<li>
			If <m> AB </m> has a row of zeros for some <m>A\neq 0</m>, so also does <m> B </m>.			
		</li>
	</ol>

			</statement>
						<solution>
							<ol>
							 <li><solution>
							 	<!--If <m> B</m>  has a row of zeros, so also does <m> AB</m> for all <m> A</m>. -->
							 	<em>False:</em> Let
							 	<me>
							 		A=\begin{bmatrix} 1 \amp 1 \\ 1 \amp 1 \end{bmatrix} 
									\text{ and }									
									B=\begin{bmatrix} 1 \amp 0 \\ 0 \amp 0 \end{bmatrix}.
								</me>
								Then <m>AB = \begin{bmatrix} 1 \amp 0 \\ 1 \amp 0 \end{bmatrix}</m> does not have a zero row.
							</solution></li>							
							<li><solution>  
								<!-- If <m> A </m> has a row of zeros, so also does <m> AB </m> for all <m> B</m>. -->
								<em>True:</em> Let us write <m>A= [ a_{ij}]</m> and <m>B= [ b_{jk}]</m>. By assumption, there exists a zero row in <m>A</m>, say row <m>i_{0}</m>. In other words, <m>a_{i_{0}j}=0</m> for all <m>j</m>. By definition of <m>AB= [c_{ik}]</m> (see <xref ref="hint-matrix-product"/>), its <m>(i,k)</m>-entry is defined by
								<me>
									c_{ik} = a_{i1}b_{1k}+a_{i2}b_{2k}+...+a_{in}b_{nk}.
								</me>
								Since <m>a_{i_{0}j}=0</m> for all <m>j</m>, we see that <m>c_{i_{0}k}=0</m> for all <m>k</m>. In other words, row <m>i_{0}</m> in <m>AB</m> is zero.
							</solution></li>
							<li><solution>
								<!-- If <m> B</m> has a column of zeros, so also does <m> AB </m>  for all <m>A</m>. -->
								<em>True:</em> Let us write <m>A= [ a_{ij}]</m> and <m>B= [ b_{jk}]</m>. By assumption, there exists a zero column in <m>B</m>, say column <m>k_{0}</m>. In other words, <m>b_{jk_{0}}=0</m> for all <m>j</m>. By definition of <m>AB= [c_{ik}]</m> (see <xref ref="hint-matrix-product"/>), its <m>(i,k)</m>-entry is defined by
								<me>
									c_{ik} = a_{i1}b_{1k}+a_{i2}b_{2k}+...+a_{in}b_{nk}.
								</me>
								Since <m>b_{jk_{0}}=0</m> for all <m>j</m>, we see that <m>c_{ik_{0}}=0</m> for all <m>i</m>. In other words, column <m>k_{0}</m> in <m>AB</m> is zero.
							</solution></li>
							<li><solution> 
								<!-- If <m> AB </m> has a column of zeros for some <m>A\neq 0</m>, then so also does <m> B</m>. -->
								<em>False:</em> Take 
								<me>
									A=\begin{bmatrix} 1 \amp -2 \\ 2 \amp -4 \end{bmatrix} 
									\text{ and }
									B=\begin{bmatrix} 2 \amp 4 \\ 1 \amp 2 \end{bmatrix},
								</me>
								so that
								<me>
									AB 
									=\begin{bmatrix} 0 \amp 0 \\ 0 \amp 0 \end{bmatrix} .
								</me>
							</solution></li>
							<li><solution> 
								<!-- If <m> AB </m> has a row of zeros for some <m>A\neq 0</m>, so also does <m> B </m>.	 -->
								<em>False:</em> Take
								<me>
									A=\begin{bmatrix} 1 \amp -2 \\ 2 \amp -4 \end{bmatrix} 
									\text{ and }
									B=\begin{bmatrix} 2 \amp 4 \\ 1 \amp 2 \end{bmatrix},
								</me>
								so that
								<me>
									AB 
									=\begin{bmatrix} 0 \amp 0 \\ 0 \amp 0 \end{bmatrix} .
								</me>
							</solution></li>
						</ol>
						</solution>
						<answer>
							<ol>
							 <li>
							 	<!--If <m> B</m>  has a row of zeros, so also does <m> AB</m> for all <m> A</m>. -->
							 	False.
							</li>							
							<li><!-- If <m> A </m> has a row of zeros, so also does <m> AB </m> for all <m> B</m>. -->
								True.</li>
							<li><!-- If <m> B</m> has a column of zeros, so also does <m> AB </m>  for all <m>A</m>. -->
								True.</li>
							<li><!-- If <m> AB </m> has a column of zeros for some <m>A\neq 0</m>, then so also does <m> B</m>. -->
								False. 
							</li>
							<li><!-- If <m> AB </m> has a row of zeros for some <m>A\neq 0</m>, so also does <m> B </m>.	 -->
								False.</li>
						</ol>
						</answer>

					</exercise></p>

					<p><exercise><!-- xml:id="ex-" -->
						<statement>
							<aside><p> (Source: <xref ref="ref-KK" />, Chapter 2, Exercise 2.1.15) </p></aside>
							Let <m>A = \begin{bmatrix} 1 \amp 2 \\ 3 \amp 4 \end{bmatrix}</m> and <m> B = \begin{bmatrix} 1 \amp 2 \\ 1 \amp k \end{bmatrix}</m>.  Is it possible to find <m>k</m> such that <m> AB = BA</m>? If so, what should <m> k </m> equal? 
						</statement>
						<hint>
							Compute both <m>AB</m> and <m>BA</m> and compare the answer.
						</hint>
						<solution>
							We compute
							<me>
								AB = \begin{bmatrix} 3 \amp 2+2k \\ 7 \amp 6+4k \end{bmatrix}
								\text{ and }
								BA = \begin{bmatrix} 7 \amp 10 \\ 1+3k \amp 6+4k \end{bmatrix}.
							</me>
							For these to be equal, we need them to be equal entrywise, but no matter what <m>k</m> we choose, the <m>(1,1)</m>-entries will never coincide (<m>3\neq 7</m>). Thus, the answer is no.
					</solution>
						<answer>
							No.
						</answer>
					</exercise></p>


					<p><exercise><!-- xml:id="ex-" -->
						<statement>
							<aside><p> (Source: <xref ref="ref-PS" />, Chapter 6, Exercise 6.4.4) </p></aside>
							Find the matrix of the linear transformation that reflects every vector in <m> \mathbb{R}^2 </m> about the <m>x</m>-axis and then rotates by an angle of <m> \frac{\pi}{4}. </m>							
						</statement>
						<hint>
							You might want to combine the solution to <xref ref="ex-matrix-of-reflection-about-x-axis"/> and (a variant of) <xref ref="ex-matr-of-rot"/> by using <xref ref="ex-comp-of-transf-equals-mult-of-matr"/>. Be careful with the correct order of operation!
						</hint>
						<!-- <solution>
						</solution> -->
						<!--<answer>
						</answer> -->
					</exercise></p>




						<p><exercise><!-- xml:id="ex-" -->
						<statement>
							<aside><p> (Source: <xref ref="ref-PS" />, Chapter 6, Exercise 6.4.3) </p></aside>
							Find the matrix of the linear transformation that rotates every vector in <m> \mathbb{R}^2 </m> by an angle of <m> \frac{\pi}{6} </m> and then reflects about the <m>x</m>-axis, followed by a reflection about the <m>y</m>-axis. 						
						</statement>
						<hint>
							You might want to combine previous solutions by using <xref ref="ex-comp-of-transf-equals-mult-of-matr"/>. Be careful with the correct order of operation!
						</hint>
						<!--<solution>
						</solution>-->
						<!--<answer>
						</answer> -->
					</exercise></p>
					
				</exercises>
		