<section xml:id="sec-SLERevisted" xmlns:xi="http://www.w3.org/2001/XInclude">

	<title>
		Systems of linear equations revisited
	</title>
	<introduction>
		<p> We introduced techniques for solving systems of linear equations in <xref ref="sec-Elimination" />.  With the understanding of vectors that we have developed since then we are now ready to make a more detailed study of systems of linear equations. </p>
	</introduction>

	<subsection>
		<title> Rank </title>

		<definition>
			<p>Let <m>A</m> be a matrix.  A <em>pivot column</em> of <m>A</m> is a column of <m>A</m> that corresponds to a column of <m>\RREF(A)</m> containing the leading <m>1</m> of some row.</p>
			<p>The <em>rank</em> of <m>A</m>, written <m>\rank(A)</m>, is the number of pivot columns of <m>A</m>.</p>
		</definition>
		<example>
		</example>

		<lemma xml:id="lem-pivot-nonzero-row">
			<statement>
				<p> Let <m>A</m> be a matrix.  Then <m>\rank(A)</m> is equal to the number of non-zero rows of <m>\RREF(A)</m>.</p>
			</statement>
			<proof>

			</proof>
		</lemma>

		<p>The reason for the word "nullity" in the name of the next theorem will be given in <xref ref="sec-Matrix-Subspaces" />.</p>

		<theorem xml:id="thm-rank-nullity-version-1">
			<title> Rank-Nullity Theorem </title>
			<statement>
				<p> In a consistent system of linear equations with <m>n</m> variables, if <m>A</m> is the coefficient matrix of the system, then <me>\rank(A) + \text{# of free variables of the system} = n</me>.</p>
			</statement>
			<proof>
				<p> Suppose our system is <m>[A|\vec{b}]</m>.  After row-reducing we see that the non-pivot columns of <m>A</m> correspond to free variables of the system, so 
				<md>
					<mrow>\rank(A) + \amp \text{# of free variables of the system}</mrow>
					<mrow> \amp = \text{# of pivot columns of} A + \text{# of non-pivot columns of} A</mrow>
					<mrow> \amp = \text{# of columns of} A </mrow>
					<mrow> \amp = n</mrow>
				</md>.</p>
			</proof>
		</theorem>

		<example>
		</example>

		<corollary>
			<statement>
				<p> Any system of linear equations has either no solution, exactly one solution, or infinitely many solutions. </p>
			</statement>
			<proof>
				<p> Suppose that we have a system <m>[A|\vec{b}]</m>, where <m>A</m> is an <m>m \times n</m> matrix.  There are three possibilities:
				<ul>
					<li> The system is inconsistent.  In this case it has no solutions, by definition. </li>
					<li> The system is consistent and <m>\rank(A) = n</m>.  Then every column of <m>A</m> is a pivot column and (by <xref ref="lem-pivot-nonzero-row" />) there are exactly <m>n</m> non-zero rows of <m>\RREF(A)</m>, so the form of the reduced row echelon form of the system is <m>\matr{cccc|c}{1 \amp 0 \amp \cdots \amp 0 \amp c_1 \\ 0 \amp 1 \amp \cdots \amp 0 \amp c_2 \\ \vdots \amp \vdots \amp \ddots \amp \vdots \amp \vdots \\ 0 \amp 0 \amp \cdots \amp 1 \amp c_n \\ 0 \amp 0 \amp \cdots \amp 0 \amp 0 \\ \vdots \amp \vdots \amp \ddots \amp \vdots \amp \vdots \\ 0 \amp 0 \amp \cdots \amp 0 \amp 0}</m>.  A system of this form has unique solution <m>x_1 = c_1, \ldots, x_n = c_n</m>. </li>
					<li> The system is consistent and <m>\rank(A) \lt n</m>.  Then by <xref ref="thm-rank-nullity-version-1" /> the system has at least one free variable, and since each value of the free variable gives rise to a solution the system has infinitely many solutions. </li>
				</ul>
				</p>
			</proof>
		</corollary>
	</subsection>
	<subsection>
		<title> Homogeneous systems </title>
		<definition>
			<p> A system of linear equations is called <em>homogeneous</em> if all of the constants on the right of the equals signs are <m>0</m>.  That is, if the augmented matrix of the system has the form <m>[A|\vec{0}]</m>.</p>
		</definition>
		<note>
			<p> Homogeneous systems are exactly the ones that arose in <xref ref="sec-LinearIndependence" /> when we tested whether or not a collection of vectors is linearly independent. </p>
			<p> Every homogeneous system is consistent - just choose the values of all of the variables to be <m>0</m>.  There may or may not be other solutions, depending on the system.</p>
		</note>
		<theorem xml:id="thm-homogeneous-system-more-variables">
			<statement>
				<p> If a homogeneous system has more variables than equations then it has infinitely many solutions. </p>
			</statement>
			<proof>
				<p> Suppose that the system <m>[A|\vec{0}]</m> has <m>n</m> variables and <m>m</m> equations (so <m>A</m> is an <m>m \times n</m> matrix), with <m>m \lt n</m>.  Then, by <xref ref="thm-rank-nullity-version-1" />,
				<md>
					<mrow>\text{# free variables} \amp = n - \rank(A)</mrow>
					<mrow>\amp \geq n - m</mrow>
					<mrow> \amp \gt 0</mrow>
				</md>.  Thus the system has at least one free variable, so it has infinitely many solutions. </p>
			</proof>
		</theorem>

		<theorem xml:id="thm-more-vectors-than-dimension">
			<statement>
				<p> If <m>k > n</m> then every collection of <m>k</m> distinct vectors in <m>\mathbb{R}^n</m> is linearly dependent.</p>
			</statement>
			<proof>
				<p>Suppose that <m>\vec{v_1}, \ldots, \vec{v_k}</m> are distinct vectors in <m>\mathbb{R}^n</m>, with <m>k \geq n</m>, and let <m>A</m> be the matrix with columns <m>\vec{v_1}, \ldots, \vec{v_k}</m>.  Then the system <m>[A|\vec{0}]</m> is a homogeneous system with more variables (<m>k</m>) than equations (<m>n</m>), so by <xref ref="thm-homogeneous-system-more-variables" /> this system has infinitely many solutions.  In particular, it does not have a unique solution, so by <xref ref="thm-indep-iff-unique-solution" /> the vectors <m>\vec{v_1}, \ldots, \vec{v_k}</m> are linearly dependent.</p>
			</proof>
		</theorem>

		<note>
			<p> If we have a homogeneous system with <m>n</m> variables and <m>m</m> equations with <m>m \geq n</m> then <xref ref="thm-homogeneous-system-more-variables" /> does not apply.  The system could have exactly one solution or it could have infinitely many solutions, depending on the specific system. </p>
			<p> Similarly, if we have <m>k</m> vectors in <m>\mathbb{R}^n</m> with <m>k \leq n</m> then <xref ref="thm-more-vectors-than-dimension" /> does not apply.  The vectors could be linearly dependent or linearly independent, depending on the specific vectors. </p>
		</note>

		<example>
			<p> The vectors <m>\begin{bmatrix}1\\0\\2\\1\end{bmatrix}, \begin{bmatrix}-3\\ \pi \\ 1 \\ 1\end{bmatrix}, \begin{bmatrix}1 \\ 1\\ 1\\ 1\end{bmatrix}, \begin{bmatrix}15 \\ -\sqrt{2} \\ 3 \\ 1\end{bmatrix}, \begin{bmatrix} 0 \\ 1 \\ 0 \\1\end{bmatrix}</m> form a linearly dependent set, because they are <m>5</m> vectors in <m>\mathbb{R}^4</m>.  If we wanted to actually find a non-trivial linear combination of these vectors that equals <m>\vec{0}</m> we could follow the methods from <xref ref="sec-LinearIndependence" />, but if all we need to know is that they are linearly dependent then no calculation is required. </p>
			<p> By contrast, the vectors <m>\begin{bmatrix}1\\0\\2\\1\end{bmatrix}, \begin{bmatrix}-3\\ \pi \\ 1 \\ 1\end{bmatrix}, \begin{bmatrix}1 \\ 1\\ 1\\ 1\end{bmatrix}</m> might be linearly dependent or linearly independent - without doing any calculations there is no way to tell.  In fact, they are independent, as you can check. </p>
		</example>
	</subsection>

	<subsection>
		<title> The fundamental theorem </title>

		<p> The next theorem is very important - so important that it is often called the "Fundamental Theorem of Linear Algebra".  As the course goes on we will be adding to this theorem, and it will eventually grow to touch nearly every topic of the course.  Before stating it we need one definition (which will reappear in <xref ref="sec-Multiplication" />).</p>
		<definition>
			<p> For any natural number <m>n</m>, the <em><m>n \times n</m> identity matrix</em> is the <m>n \times n</m> matrix <m>I_n = \begin{bmatrix}1 \amp 0 \amp 0 \amp \cdots \amp 0 \\ 0 \amp 1 \amp 0 \amp \cdots \amp 0 \\ 0 \amp 0 \amp 1 \amp \cdots \amp 0 \\ \vdots \amp \vdots \amp \vdots \amp \ddots \amp \vdots \\ 0 \amp 0 \amp 0 \amp \cdots \amp 1\end{bmatrix}</m>.</p>
		</definition>

		<theorem xml:id="thm-fundamental-version-1">
			<title> Fundamental Theorem - Version 1 </title>
			<statement>
				<p> Let <m>A</m> be an <m>n \times n</m> (non-augmented) matrix.  The following are equivalent: </p>
				<ol>
					<li> <m>\RREF(A) = I_n</m>.</li>
					<li> The system <m>[A|\vec{0}]</m> has a unique solution. </li>
					<li> For every vector <m>\vec{b}</m> in <m>\mathbb{R}^n</m>, the system <m>[A|\vec{b}]</m> has a unique solution.</li>
					<li> The columns of <m>A</m> are linearly independent. </li>
					<li> The span of the columns of <m>A</m> is <m>\mathbb{R}^n</m>. </li>
					<li> <m>\rank(A) = n</m>.</li>
				</ol>
			</statement>
			<proof>
			</proof>
		</theorem>
	</subsection>



	<xi:include href="2-1-exercises.ptx" />
</section>